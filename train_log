Total_no_of_cpu_count 24
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
Enviroment_id SpaceInvaders-v0
##########################No_of_enviroments############### <subproc_vec_env.SubprocVecEnv object at 0x7ffbdbc60748>
WARNING:tensorflow:From /home/shariq/Desktop/a2c_trial/a2c.py:200: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/shariq/Desktop/a2c_trial/a2c.py:14: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/shariq/Desktop/a2c_trial/a2c.py:52: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/shariq/Desktop/a2c_trial/a2c.py:55: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/shariq/Desktop/a2c_trial/a2c.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/shariq/Desktop/a2c_trial/neural_network.py:14: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffb1adbf278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffb1adbf278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffb56ec2c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffb56ec2c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffb56ec2c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffb56ec2c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /home/shariq/Desktop/a2c_trial/neural_network.py:130: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ffb18228cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ffb18228cc0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /home/shariq/Desktop/a2c_trial/neural_network.py:19: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffb18145630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffb18145630>>: AssertionError: Bad argument number for Name: 3, expecting 4
nbatch 24 nsteps 1
batch_to_seq Tensor("model/Reshape:0", shape=(24, 1, 512), dtype=float32)
nbatch 24 nsteps 1
batch_to_seq Tensor("model/Reshape_1:0", shape=(24, 1, 1), dtype=float32)
shape_of_snew (24, 256)
Shape_of_h4 (24, 512)
Shape_of_M Tensor("Placeholder_5:0", shape=(24,), dtype=float32)
Shape_of_S Tensor("Placeholder_6:0", shape=(24, 256), dtype=float32)
Shape_of_xs 1 (24, 128)
Shape_of_ms 1 (24, 1)
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffb180826a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffb180826a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffb180826a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffb180826a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffac0545668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffac0545668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffac0545668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffac0545668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffac0545668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffac0545668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ffac0545358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ffac0545358>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffac0545668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffac0545668>>: AssertionError: Bad argument number for Name: 3, expecting 4
nbatch 24 nsteps 12
batch_to_seq Tensor("model_1/Reshape:0", shape=(24, 12, 512), dtype=float32)
nbatch 24 nsteps 12
batch_to_seq Tensor("model_1/Reshape_1:0", shape=(24, 12, 1), dtype=float32)
shape_of_snew (24, 256)
Shape_of_h4 (288, 512)
Shape_of_M Tensor("Placeholder_8:0", shape=(288,), dtype=float32)
Shape_of_S Tensor("Placeholder_9:0", shape=(24, 256), dtype=float32)
Shape_of_xs 12 (24, 128)
Shape_of_ms 12 (24, 1)
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffac0468208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffac0468208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffb181a7cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7ffb181a7cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
Dictionory_of_train {'state': <tf.Tensor 'Const_2:0' shape=(0,) dtype=float32>, 'lstm_states': <tf.Tensor 'Const_3:0' shape=(0,) dtype=float32>, 'initial_state': array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]]), 'X': <tf.Tensor 'Placeholder_7:0' shape=(288, 84, 84, 4) dtype=uint8>, 'M': <tf.Tensor 'Placeholder_8:0' shape=(288,) dtype=float32>, 'S': <tf.Tensor 'Placeholder_9:0' shape=(24, 256) dtype=float32>, 'pi': <tf.Tensor 'model_1/dense_1/BiasAdd:0' shape=(288, 6) dtype=float32>, 'vf': <tf.Tensor 'model_1/dense_2/BiasAdd:0' shape=(288, 1) dtype=float32>, 'step': <function CNN.__init__.<locals>.step at 0x7ffb1ae02d90>, 'value': <function CNN.__init__.<locals>.value at 0x7ffb1ae6aae8>}
WARNING:tensorflow:From /home/shariq/anaconda3/envs/reinforcement/lib/python3.6/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/shariq/Desktop/a2c_trial/a2c.py:89: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

WARNING:tensorflow:From /home/shariq/anaconda3/envs/reinforcement/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 1
current_timesteps 1
fps 172
policy_entropy 1.79134202003479
value_loss 0.1989019215106964
total_no 305556
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 1000
current_timesteps 1000
fps 1149
policy_entropy 1.5671610832214355
value_loss 0.49226081371307373
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 3.51
max (last 100): 17.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 2000
current_timesteps 2000
fps 1161
policy_entropy 1.520188331604004
value_loss 0.1852429360151291
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 3.47
max (last 100): 12.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 3000
current_timesteps 3000
fps 1174
policy_entropy 1.413629174232483
value_loss 0.24864636361598969
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 4.46
max (last 100): 9.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 4000
current_timesteps 4000
fps 1192
policy_entropy 1.4927767515182495
value_loss 0.22542816400527954
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 5.05
max (last 100): 21.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 5000
current_timesteps 5000
fps 1196
policy_entropy 1.297332525253296
value_loss 0.8297991752624512
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 3.87
max (last 100): 16.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 6000
current_timesteps 6000
fps 1198
policy_entropy 1.258171558380127
value_loss 0.3141368329524994
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 6.16
max (last 100): 19.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 7000
current_timesteps 7000
fps 1201
policy_entropy 1.3236260414123535
value_loss 0.1880241334438324
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 5.81
max (last 100): 31.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 8000
current_timesteps 8000
fps 1207
policy_entropy 0.8120402097702026
value_loss 0.3158606290817261
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 5.19
max (last 100): 24.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 9000
current_timesteps 9000
fps 1211
policy_entropy 1.0829463005065918
value_loss 0.055179961025714874
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 5.65
max (last 100): 20.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 10000
current_timesteps 10000
fps 1216
policy_entropy 1.255566954612732
value_loss 0.18634697794914246
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 6.01
max (last 100): 20.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 11000
current_timesteps 11000
fps 1220
policy_entropy 0.939184844493866
value_loss 0.3855305314064026
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 6.66
max (last 100): 24.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 12000
current_timesteps 12000
fps 1223
policy_entropy 0.9849441051483154
value_loss 0.4906046688556671
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 6.77
max (last 100): 26.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 13000
current_timesteps 13000
fps 1224
policy_entropy 0.6316030025482178
value_loss 0.560032069683075
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 5.92
max (last 100): 20.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 14000
current_timesteps 14000
fps 1225
policy_entropy 0.6489382982254028
value_loss 0.658659040927887
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 7.31
max (last 100): 27.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 15000
current_timesteps 15000
fps 1227
policy_entropy 0.7240011692047119
value_loss 0.5243967175483704
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 7.89
max (last 100): 30.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 16000
current_timesteps 16000
fps 1229
policy_entropy 0.6087381839752197
value_loss 0.44091054797172546
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 7.9
max (last 100): 26.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 17000
current_timesteps 17000
fps 1230
policy_entropy 0.7596690654754639
value_loss 0.2942437529563904
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 8.25
max (last 100): 34.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 18000
current_timesteps 18000
fps 1240
policy_entropy 0.8328713774681091
value_loss 0.5931943655014038
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 7.59
max (last 100): 25.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 19000
current_timesteps 19000
fps 1253
policy_entropy 0.7729912996292114
value_loss 0.93114173412323
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 10.48
max (last 100): 35.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 20000
current_timesteps 20000
fps 1263
policy_entropy 0.6720320582389832
value_loss 1.1189961433410645
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 7.65
max (last 100): 29.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 21000
current_timesteps 21000
fps 1262
policy_entropy 0.8897032141685486
value_loss 1.0299478769302368
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 8.92
max (last 100): 34.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 22000
current_timesteps 22000
fps 1263
policy_entropy 0.7773752808570862
value_loss 0.27333176136016846
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 8.94
max (last 100): 29.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 23000
current_timesteps 23000
fps 1263
policy_entropy 0.806687593460083
value_loss 0.5599716901779175
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 7.44
max (last 100): 27.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 24000
current_timesteps 24000
fps 1263
policy_entropy 1.0374258756637573
value_loss 1.2687456607818604
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 9.5
max (last 100): 33.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 25000
current_timesteps 25000
fps 1264
policy_entropy 0.7681393027305603
value_loss 1.2991911172866821
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 10.12
max (last 100): 34.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 26000
current_timesteps 26000
fps 1264
policy_entropy 0.9120394587516785
value_loss 0.9080302119255066
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 9.4
max (last 100): 34.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 27000
current_timesteps 27000
fps 1265
policy_entropy 0.7550099492073059
value_loss 0.5345912575721741
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 9.5
max (last 100): 33.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 28000
current_timesteps 28000
fps 1265
policy_entropy 0.9015572667121887
value_loss 0.6696818470954895
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 10.42
max (last 100): 35.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 29000
current_timesteps 29000
fps 1266
policy_entropy 0.9533669948577881
value_loss 1.1214661598205566
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 9.47
max (last 100): 35.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 30000
current_timesteps 30000
fps 1266
policy_entropy 0.9363978505134583
value_loss 1.2186344861984253
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 10.41
max (last 100): 41.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 31000
current_timesteps 31000
fps 1267
policy_entropy 0.9145090579986572
value_loss 0.3733270466327667
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 10.97
max (last 100): 37.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 32000
current_timesteps 32000
fps 1268
policy_entropy 0.8655225038528442
value_loss 0.35573452711105347
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 10.75
max (last 100): 33.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 33000
current_timesteps 33000
fps 1268
policy_entropy 1.0399854183197021
value_loss 0.7868161797523499
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 10.92
max (last 100): 37.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 34000
current_timesteps 34000
fps 1269
policy_entropy 1.0016189813613892
value_loss 0.30772143602371216
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 9.06
max (last 100): 32.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 35000
current_timesteps 35000
fps 1270
policy_entropy 0.9203871488571167
value_loss 0.5114969611167908
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 10.9
max (last 100): 33.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 36000
current_timesteps 36000
fps 1271
policy_entropy 0.8645312786102295
value_loss 0.4651198983192444
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 11.57
max (last 100): 48.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 37000
current_timesteps 37000
fps 1272
policy_entropy 0.8882779479026794
value_loss 0.5621987581253052
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 13.1
max (last 100): 46.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 38000
current_timesteps 38000
fps 1273
policy_entropy 1.076640009880066
value_loss 0.8553594946861267
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 12.14
max (last 100): 35.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 39000
current_timesteps 39000
fps 1274
policy_entropy 0.8148306608200073
value_loss 0.4208832383155823
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 12.01
max (last 100): 40.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 40000
current_timesteps 40000
fps 1275
policy_entropy 0.8156993389129639
value_loss 0.38713210821151733
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 11.73
max (last 100): 33.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 41000
current_timesteps 41000
fps 1276
policy_entropy 0.7732573747634888
value_loss 1.7645926475524902
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 13.04
max (last 100): 36.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 42000
current_timesteps 42000
fps 1277
policy_entropy 0.8738387227058411
value_loss 1.1726069450378418
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 13.93
max (last 100): 58.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 43000
current_timesteps 43000
fps 1278
policy_entropy 0.8099164962768555
value_loss 0.4724401831626892
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 12.25
max (last 100): 45.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 44000
current_timesteps 44000
fps 1279
policy_entropy 0.791155219078064
value_loss 0.32137203216552734
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 13.77
max (last 100): 57.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 45000
current_timesteps 45000
fps 1280
policy_entropy 0.8188869953155518
value_loss 0.4326220750808716
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 14.54
max (last 100): 52.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 46000
current_timesteps 46000
fps 1281
policy_entropy 0.7126176357269287
value_loss 0.6486029624938965
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 15.36
max (last 100): 60.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 47000
current_timesteps 47000
fps 1282
policy_entropy 0.6619268655776978
value_loss 0.6081244945526123
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 14.09
max (last 100): 56.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 48000
current_timesteps 48000
fps 1283
policy_entropy 0.5816351771354675
value_loss 1.5024405717849731
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 15.0
max (last 100): 65.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 49000
current_timesteps 49000
fps 1284
policy_entropy 0.5685935616493225
value_loss 1.6364588737487793
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 16.09
max (last 100): 68.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 50000
current_timesteps 50000
fps 1285
policy_entropy 0.48022741079330444
value_loss 0.16373522579669952
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 16.05
max (last 100): 69.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 51000
current_timesteps 51000
fps 1286
policy_entropy 0.561083197593689
value_loss 0.3840562105178833
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 15.97
max (last 100): 65.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 52000
current_timesteps 52000
fps 1287
policy_entropy 0.6248780488967896
value_loss 0.486657977104187
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 16.21
max (last 100): 61.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 53000
current_timesteps 53000
fps 1288
policy_entropy 0.678532063961029
value_loss 1.2620165348052979
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 17.7
max (last 100): 69.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 54000
current_timesteps 54000
fps 1289
policy_entropy 0.5874645709991455
value_loss 0.19516880810260773
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 16.9
max (last 100): 71.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 55000
current_timesteps 55000
fps 1290
policy_entropy 0.4685235023498535
value_loss 0.17094530165195465
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 18.8
max (last 100): 86.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 56000
current_timesteps 56000
fps 1291
policy_entropy 0.7479963898658752
value_loss 0.15198856592178345
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 20.61
max (last 100): 79.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 57000
current_timesteps 57000
fps 1292
policy_entropy 0.4990324378013611
value_loss 0.21752184629440308
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 16.96
max (last 100): 79.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 58000
current_timesteps 58000
fps 1293
policy_entropy 0.41250714659690857
value_loss 0.40773651003837585
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 21.43
max (last 100): 83.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 59000
current_timesteps 59000
fps 1294
policy_entropy 0.6480281352996826
value_loss 0.8383499383926392
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 20.6
max (last 100): 72.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 60000
current_timesteps 60000
fps 1295
policy_entropy 0.5727062225341797
value_loss 0.4424173831939697
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 22.99
max (last 100): 104.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 61000
current_timesteps 61000
fps 1296
policy_entropy 0.5792429447174072
value_loss 0.21707981824874878
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 22.2
max (last 100): 72.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 62000
current_timesteps 62000
fps 1297
policy_entropy 0.5706982612609863
value_loss 1.5636117458343506
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 23.33
max (last 100): 78.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 63000
current_timesteps 63000
fps 1298
policy_entropy 0.5612719655036926
value_loss 0.9724404215812683
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 22.34
max (last 100): 103.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 64000
current_timesteps 64000
fps 1299
policy_entropy 0.5585166215896606
value_loss 0.8769432902336121
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 24.85
max (last 100): 105.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 65000
current_timesteps 65000
fps 1300
policy_entropy 0.4070514440536499
value_loss 2.0770747661590576
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 23.88
max (last 100): 89.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 66000
current_timesteps 66000
fps 1301
policy_entropy 0.5578715205192566
value_loss 1.274873971939087
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 21.74
max (last 100): 71.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 67000
current_timesteps 67000
fps 1302
policy_entropy 0.42137035727500916
value_loss 0.579098641872406
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 22.71
max (last 100): 94.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 68000
current_timesteps 68000
fps 1303
policy_entropy 0.5639406442642212
value_loss 0.6890348792076111
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 20.8
max (last 100): 72.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 69000
current_timesteps 69000
fps 1304
policy_entropy 0.46130070090293884
value_loss 3.2145910263061523
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 27.06
max (last 100): 107.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 70000
current_timesteps 70000
fps 1305
policy_entropy 0.5939885973930359
value_loss 0.5583049654960632
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 21.44
max (last 100): 107.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 71000
current_timesteps 71000
fps 1306
policy_entropy 0.45509612560272217
value_loss 0.6592694520950317
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 21.53
max (last 100): 79.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 72000
current_timesteps 72000
fps 1306
policy_entropy 0.5582392811775208
value_loss 0.9185912013053894
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 20.3
max (last 100): 101.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 73000
current_timesteps 73000
fps 1307
policy_entropy 0.42516735196113586
value_loss 0.8300848603248596
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 23.69
max (last 100): 80.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 74000
current_timesteps 74000
fps 1308
policy_entropy 0.5643007159233093
value_loss 0.7516994476318359
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 27.54
max (last 100): 89.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 75000
current_timesteps 75000
fps 1309
policy_entropy 0.5106950402259827
value_loss 0.446820467710495
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 27.96
max (last 100): 103.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 76000
current_timesteps 76000
fps 1310
policy_entropy 0.48918697237968445
value_loss 0.7856748104095459
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 24.39
max (last 100): 101.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 77000
current_timesteps 77000
fps 1311
policy_entropy 0.4728321433067322
value_loss 0.46207523345947266
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 28.09
max (last 100): 116.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 78000
current_timesteps 78000
fps 1311
policy_entropy 0.4903780221939087
value_loss 0.7571122646331787
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 24.43
max (last 100): 81.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 79000
current_timesteps 79000
fps 1312
policy_entropy 0.48524391651153564
value_loss 0.3127230405807495
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 27.53
max (last 100): 103.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 80000
current_timesteps 80000
fps 1313
policy_entropy 0.46580109000205994
value_loss 0.2584037780761719
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 27.1
max (last 100): 124.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 81000
current_timesteps 81000
fps 1314
policy_entropy 0.5716242790222168
value_loss 0.3927391767501831
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 30.32
max (last 100): 127.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 82000
current_timesteps 82000
fps 1315
policy_entropy 0.42798441648483276
value_loss 0.19617444276809692
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 25.12
max (last 100): 111.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 83000
current_timesteps 83000
fps 1315
policy_entropy 0.5586001873016357
value_loss 1.0642892122268677
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 27.23
max (last 100): 94.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 84000
current_timesteps 84000
fps 1316
policy_entropy 0.5336208343505859
value_loss 2.261303663253784
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 26.89
max (last 100): 107.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 85000
current_timesteps 85000
fps 1317
policy_entropy 0.44121837615966797
value_loss 0.7533532977104187
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 26.59
max (last 100): 75.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 86000
current_timesteps 86000
fps 1318
policy_entropy 0.5391790866851807
value_loss 0.43218353390693665
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 32.5
max (last 100): 152.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 87000
current_timesteps 87000
fps 1318
policy_entropy 0.44740766286849976
value_loss 0.8518347144126892
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 28.68
max (last 100): 127.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 88000
current_timesteps 88000
fps 1319
policy_entropy 0.540448009967804
value_loss 0.5976150631904602
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 33.85
max (last 100): 108.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 89000
current_timesteps 89000
fps 1320
policy_entropy 0.5193222165107727
value_loss 0.3196251690387726
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 36.52
max (last 100): 112.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 90000
current_timesteps 90000
fps 1321
policy_entropy 0.47005027532577515
value_loss 1.3413615226745605
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 28.03
max (last 100): 112.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 91000
current_timesteps 91000
fps 1321
policy_entropy 0.38901785016059875
value_loss 0.3948146104812622
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 32.34
max (last 100): 99.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 92000
current_timesteps 92000
fps 1322
policy_entropy 0.4546584486961365
value_loss 2.7780261039733887
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 27.34
max (last 100): 101.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 93000
current_timesteps 93000
fps 1323
policy_entropy 0.4667752981185913
value_loss 3.886139392852783
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 39.27
max (last 100): 108.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 94000
current_timesteps 94000
fps 1323
policy_entropy 0.42344459891319275
value_loss 1.3375635147094727
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 33.69
max (last 100): 139.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 95000
current_timesteps 95000
fps 1324
policy_entropy 0.44000107049942017
value_loss 0.5657332539558411
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 32.99
max (last 100): 138.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 96000
current_timesteps 96000
fps 1325
policy_entropy 0.4890478849411011
value_loss 0.41517701745033264
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 32.75
max (last 100): 143.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 97000
current_timesteps 97000
fps 1326
policy_entropy 0.47208595275878906
value_loss 0.462115079164505
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 35.76
max (last 100): 149.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 98000
current_timesteps 98000
fps 1326
policy_entropy 0.48570525646209717
value_loss 1.9094194173812866
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 34.19
max (last 100): 137.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 99000
current_timesteps 99000
fps 1327
policy_entropy 0.41915032267570496
value_loss 0.3056493103504181
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 36.98
max (last 100): 125.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 100000
current_timesteps 100000
fps 1327
policy_entropy 0.4700954854488373
value_loss 1.406134843826294
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 30.52
max (last 100): 108.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 101000
current_timesteps 101000
fps 1328
policy_entropy 0.5107062458992004
value_loss 0.33673593401908875
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 32.78
max (last 100): 105.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 102000
current_timesteps 102000
fps 1329
policy_entropy 0.5065834522247314
value_loss 0.33336055278778076
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 40.84
max (last 100): 213.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 103000
current_timesteps 103000
fps 1329
policy_entropy 0.46973100304603577
value_loss 0.3191717267036438
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 34.98
max (last 100): 125.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 104000
current_timesteps 104000
fps 1330
policy_entropy 0.389428973197937
value_loss 2.7086143493652344
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 35.05
max (last 100): 129.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 105000
current_timesteps 105000
fps 1331
policy_entropy 0.44192782044410706
value_loss 0.6392073035240173
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 32.81
max (last 100): 143.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 106000
current_timesteps 106000
fps 1331
policy_entropy 0.5483004450798035
value_loss 1.5578278303146362
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 32.67
max (last 100): 137.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 107000
current_timesteps 107000
fps 1332
policy_entropy 0.41498681902885437
value_loss 0.35746023058891296
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 34.96
max (last 100): 140.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 108000
current_timesteps 108000
fps 1332
policy_entropy 0.4205697476863861
value_loss 0.31947728991508484
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 32.49
max (last 100): 123.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 109000
current_timesteps 109000
fps 1333
policy_entropy 0.41979822516441345
value_loss 0.7534797191619873
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 41.34
max (last 100): 175.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 110000
current_timesteps 110000
fps 1334
policy_entropy 0.44824695587158203
value_loss 0.6583020687103271
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 35.32
max (last 100): 141.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 111000
current_timesteps 111000
fps 1334
policy_entropy 0.44488921761512756
value_loss 2.2314512729644775
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 38.43
max (last 100): 157.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 112000
current_timesteps 112000
fps 1335
policy_entropy 0.477185994386673
value_loss 0.3643433749675751
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 41.3
max (last 100): 160.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 113000
current_timesteps 113000
fps 1336
policy_entropy 0.33152320981025696
value_loss 0.48888301849365234
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 39.06
max (last 100): 134.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 114000
current_timesteps 114000
fps 1336
policy_entropy 0.4049093425273895
value_loss 2.967460870742798
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 37.11
max (last 100): 150.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 115000
current_timesteps 115000
fps 1337
policy_entropy 0.4122314453125
value_loss 2.1354849338531494
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 43.23
max (last 100): 162.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 116000
current_timesteps 116000
fps 1337
policy_entropy 0.5323396325111389
value_loss 0.40097033977508545
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 42.83
max (last 100): 155.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 117000
current_timesteps 117000
fps 1338
policy_entropy 0.41985297203063965
value_loss 0.4531093239784241
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 41.6
max (last 100): 160.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 118000
current_timesteps 118000
fps 1339
policy_entropy 0.49494245648384094
value_loss 0.7921658754348755
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 45.84
max (last 100): 144.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 119000
current_timesteps 119000
fps 1339
policy_entropy 0.4071120619773865
value_loss 2.8040812015533447
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 44.57
max (last 100): 156.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 120000
current_timesteps 120000
fps 1340
policy_entropy 0.43443775177001953
value_loss 0.6475597620010376
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 43.53
max (last 100): 149.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 121000
current_timesteps 121000
fps 1340
policy_entropy 0.39068901538848877
value_loss 0.42749959230422974
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 40.03
max (last 100): 149.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 122000
current_timesteps 122000
fps 1341
policy_entropy 0.4028441905975342
value_loss 0.4535694718360901
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 44.17
max (last 100): 143.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 123000
current_timesteps 123000
fps 1341
policy_entropy 0.3115740120410919
value_loss 0.3271806538105011
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 50.94
max (last 100): 161.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 124000
current_timesteps 124000
fps 1342
policy_entropy 0.38105905055999756
value_loss 1.8796882629394531
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 39.89
max (last 100): 145.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 125000
current_timesteps 125000
fps 1342
policy_entropy 0.417854368686676
value_loss 4.891068458557129
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 50.26
max (last 100): 160.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 126000
current_timesteps 126000
fps 1343
policy_entropy 0.513763427734375
value_loss 0.5537538528442383
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 41.28
max (last 100): 160.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 127000
current_timesteps 127000
fps 1344
policy_entropy 0.3394756317138672
value_loss 0.37674403190612793
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 47.06
max (last 100): 151.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 128000
current_timesteps 128000
fps 1344
policy_entropy 0.4290406405925751
value_loss 4.100444316864014
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 47.69
max (last 100): 143.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 129000
current_timesteps 129000
fps 1345
policy_entropy 0.4483228325843811
value_loss 0.33234962821006775
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 51.58
max (last 100): 161.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 130000
current_timesteps 130000
fps 1345
policy_entropy 0.4438560903072357
value_loss 0.9326993227005005
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 43.13
max (last 100): 118.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 131000
current_timesteps 131000
fps 1346
policy_entropy 0.30909132957458496
value_loss 1.797454833984375
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 47.42
max (last 100): 149.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 132000
current_timesteps 132000
fps 1346
policy_entropy 0.36220258474349976
value_loss 0.4335046708583832
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 46.15
max (last 100): 193.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 133000
current_timesteps 133000
fps 1347
policy_entropy 0.48367029428482056
value_loss 0.7707197666168213
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 41.68
max (last 100): 129.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 134000
current_timesteps 134000
fps 1347
policy_entropy 0.4413178265094757
value_loss 0.7595981359481812
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 45.44
max (last 100): 208.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 135000
current_timesteps 135000
fps 1348
policy_entropy 0.35828596353530884
value_loss 0.8880677819252014
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 53.87
max (last 100): 269.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 136000
current_timesteps 136000
fps 1349
policy_entropy 0.39513087272644043
value_loss 0.31833505630493164
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 45.08
max (last 100): 152.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 137000
current_timesteps 137000
fps 1349
policy_entropy 0.4066010117530823
value_loss 0.7782032489776611
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 45.28
max (last 100): 176.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 138000
current_timesteps 138000
fps 1350
policy_entropy 0.3746218681335449
value_loss 1.9224107265472412
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 48.31
max (last 100): 226.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 139000
current_timesteps 139000
fps 1350
policy_entropy 0.42084336280822754
value_loss 0.980301558971405
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 48.84
max (last 100): 174.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 140000
current_timesteps 140000
fps 1351
policy_entropy 0.4192350506782532
value_loss 0.6218119263648987
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 51.65
max (last 100): 257.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 141000
current_timesteps 141000
fps 1351
policy_entropy 0.3507036566734314
value_loss 5.315124988555908
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 48.46
max (last 100): 244.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 142000
current_timesteps 142000
fps 1352
policy_entropy 0.416826993227005
value_loss 0.6975598335266113
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 50.6
max (last 100): 203.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 143000
current_timesteps 143000
fps 1352
policy_entropy 0.39524388313293457
value_loss 2.696439266204834
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 59.0
max (last 100): 254.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 144000
current_timesteps 144000
fps 1353
policy_entropy 0.39276373386383057
value_loss 0.5778654217720032
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 50.4
max (last 100): 160.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 145000
current_timesteps 145000
fps 1353
policy_entropy 0.4341684877872467
value_loss 0.5203759670257568
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 48.73
max (last 100): 172.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 146000
current_timesteps 146000
fps 1354
policy_entropy 0.3940695822238922
value_loss 1.1960065364837646
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 54.8
max (last 100): 197.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 147000
current_timesteps 147000
fps 1354
policy_entropy 0.3813939690589905
value_loss 1.0821421146392822
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 47.24
max (last 100): 191.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 148000
current_timesteps 148000
fps 1355
policy_entropy 0.34600383043289185
value_loss 0.2902628183364868
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 58.96
max (last 100): 281.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 149000
current_timesteps 149000
fps 1355
policy_entropy 0.3469134271144867
value_loss 1.0195634365081787
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 55.7
max (last 100): 246.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 150000
current_timesteps 150000
fps 1356
policy_entropy 0.38821694254875183
value_loss 0.27585840225219727
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 49.55
max (last 100): 223.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 151000
current_timesteps 151000
fps 1356
policy_entropy 0.4690649211406708
value_loss 1.5511335134506226
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 63.54
max (last 100): 247.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 152000
current_timesteps 152000
fps 1357
policy_entropy 0.30401143431663513
value_loss 1.1429615020751953
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 58.23
max (last 100): 237.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 153000
current_timesteps 153000
fps 1357
policy_entropy 0.354181170463562
value_loss 4.747117042541504
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 57.83
max (last 100): 248.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 154000
current_timesteps 154000
fps 1357
policy_entropy 0.4268237352371216
value_loss 0.5959234237670898
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 52.49
max (last 100): 282.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 155000
current_timesteps 155000
fps 1358
policy_entropy 0.3154227137565613
value_loss 3.264700412750244
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 60.56
max (last 100): 229.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 156000
current_timesteps 156000
fps 1358
policy_entropy 0.28341400623321533
value_loss 0.7694703936576843
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 58.62
max (last 100): 237.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 157000
current_timesteps 157000
fps 1359
policy_entropy 0.331875205039978
value_loss 0.46340212225914
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 50.51
max (last 100): 284.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 158000
current_timesteps 158000
fps 1359
policy_entropy 0.30506524443626404
value_loss 0.2991311550140381
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 60.83
max (last 100): 292.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 159000
current_timesteps 159000
fps 1360
policy_entropy 0.3129695653915405
value_loss 1.0855717658996582
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 65.94
max (last 100): 274.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 160000
current_timesteps 160000
fps 1360
policy_entropy 0.4012312889099121
value_loss 1.3445556163787842
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 64.72
max (last 100): 388.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 161000
current_timesteps 161000
fps 1361
policy_entropy 0.4489224851131439
value_loss 0.562299370765686
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 63.59
max (last 100): 206.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 162000
current_timesteps 162000
fps 1362
policy_entropy 0.3231498897075653
value_loss 4.445039749145508
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 59.43
max (last 100): 264.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 163000
current_timesteps 163000
fps 1362
policy_entropy 0.48641130328178406
value_loss 5.6441569328308105
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 58.82
max (last 100): 229.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 164000
current_timesteps 164000
fps 1363
policy_entropy 0.29905465245246887
value_loss 2.094325304031372
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 63.36
max (last 100): 225.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 165000
current_timesteps 165000
fps 1363
policy_entropy 0.3526897728443146
value_loss 1.3016797304153442
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 61.98
max (last 100): 345.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 166000
current_timesteps 166000
fps 1363
policy_entropy 0.3481982350349426
value_loss 0.359725683927536
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 61.26
max (last 100): 256.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 167000
current_timesteps 167000
fps 1365
policy_entropy 0.38460591435432434
value_loss 0.5981976985931396
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 64.76
max (last 100): 476.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 168000
current_timesteps 168000
fps 1366
policy_entropy 0.42342066764831543
value_loss 0.38995763659477234
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 70.56
max (last 100): 223.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 169000
current_timesteps 169000
fps 1368
policy_entropy 0.38828611373901367
value_loss 0.45764002203941345
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 62.84
max (last 100): 250.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 170000
current_timesteps 170000
fps 1370
policy_entropy 0.3972457945346832
value_loss 1.7965354919433594
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 70.23
max (last 100): 283.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 171000
current_timesteps 171000
fps 1371
policy_entropy 0.3764118254184723
value_loss 0.7961694002151489
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 64.47
max (last 100): 356.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 172000
current_timesteps 172000
fps 1373
policy_entropy 0.29982078075408936
value_loss 0.853512704372406
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 60.7
max (last 100): 356.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 173000
current_timesteps 173000
fps 1375
policy_entropy 0.4494290351867676
value_loss 0.5917572379112244
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 56.93
max (last 100): 370.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 174000
current_timesteps 174000
fps 1377
policy_entropy 0.4777390658855438
value_loss 0.46142783761024475
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 59.71
max (last 100): 250.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 175000
current_timesteps 175000
fps 1379
policy_entropy 0.3705844581127167
value_loss 0.5108010768890381
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 82.04
max (last 100): 352.0
Saved_the_max_model
Saved_the_model
 ^[No_of_times_loop_run 305555
 - - - - - - - 
nupdates 176000
current_timesteps 176000
fps 1380
policy_entropy 0.44041216373443604
value_loss 6.401905536651611
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 66.31
max (last 100): 321.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 177000
current_timesteps 177000
fps 1382
policy_entropy 0.46098482608795166
value_loss 1.2986688613891602
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 69.07
max (last 100): 326.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 178000
current_timesteps 178000
fps 1383
policy_entropy 0.5300470590591431
value_loss 5.620645046234131
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 64.99
max (last 100): 234.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 179000
current_timesteps 179000
fps 1385
policy_entropy 0.36645326018333435
value_loss 0.3690251111984253
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 63.71
max (last 100): 194.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 180000
current_timesteps 180000
fps 1386
policy_entropy 0.32759901881217957
value_loss 0.6163492202758789
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 60.31
max (last 100): 254.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 181000
current_timesteps 181000
fps 1388
policy_entropy 0.31990721821784973
value_loss 0.9099656343460083
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 72.31
max (last 100): 277.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 182000
current_timesteps 182000
fps 1389
policy_entropy 0.4210885465145111
value_loss 7.711113929748535
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 61.03
max (last 100): 216.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 183000
current_timesteps 183000
fps 1391
policy_entropy 0.3293430209159851
value_loss 5.485395431518555
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 64.62
max (last 100): 284.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 184000
current_timesteps 184000
fps 1392
policy_entropy 0.3291400671005249
value_loss 0.42653992772102356
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 58.56
max (last 100): 308.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 185000
current_timesteps 185000
fps 1394
policy_entropy 0.352793425321579
value_loss 0.39626115560531616
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 70.28
max (last 100): 319.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 186000
current_timesteps 186000
fps 1395
policy_entropy 0.3635297417640686
value_loss 0.5598884224891663
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 70.63
max (last 100): 313.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 187000
current_timesteps 187000
fps 1397
policy_entropy 0.343414843082428
value_loss 0.7131478786468506
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 62.32
max (last 100): 266.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 188000
current_timesteps 188000
fps 1398
policy_entropy 0.33392763137817383
value_loss 3.239584445953369
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 74.45
max (last 100): 317.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 189000
current_timesteps 189000
fps 1399
policy_entropy 0.3744772672653198
value_loss 0.46839502453804016
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 66.61
max (last 100): 289.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 190000
current_timesteps 190000
fps 1401
policy_entropy 0.33458006381988525
value_loss 1.7231531143188477
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 64.18
max (last 100): 343.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 191000
current_timesteps 191000
fps 1402
policy_entropy 0.3469808101654053
value_loss 0.3768113851547241
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 70.61
max (last 100): 263.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 192000
current_timesteps 192000
fps 1404
policy_entropy 0.3895285725593567
value_loss 0.4793227016925812
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 67.56
max (last 100): 303.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 193000
current_timesteps 193000
fps 1405
policy_entropy 0.4154179096221924
value_loss 0.5467686057090759
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 76.57
max (last 100): 297.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 194000
current_timesteps 194000
fps 1406
policy_entropy 0.3888103663921356
value_loss 7.250105857849121
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 75.59
max (last 100): 336.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 195000
current_timesteps 195000
fps 1407
policy_entropy 0.26038339734077454
value_loss 0.8918046951293945
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 68.16
max (last 100): 281.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 196000
current_timesteps 196000
fps 1409
policy_entropy 0.4092513918876648
value_loss 0.6098961234092712
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 75.95
max (last 100): 241.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 197000
current_timesteps 197000
fps 1410
policy_entropy 0.3425239622592926
value_loss 2.4239284992218018
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 66.25
max (last 100): 240.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 198000
current_timesteps 198000
fps 1411
policy_entropy 0.3856896460056305
value_loss 4.906238079071045
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 68.83
max (last 100): 287.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 199000
current_timesteps 199000
fps 1412
policy_entropy 0.3590967059135437
value_loss 0.3795775771141052
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 72.71
max (last 100): 346.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 200000
current_timesteps 200000
fps 1413
policy_entropy 0.39957746863365173
value_loss 6.047985553741455
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 55.88
max (last 100): 364.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 201000
current_timesteps 201000
fps 1415
policy_entropy 0.32864606380462646
value_loss 0.6293286085128784
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 82.36
max (last 100): 360.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 202000
current_timesteps 202000
fps 1416
policy_entropy 0.39025968313217163
value_loss 7.675321578979492
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 72.79
max (last 100): 323.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 203000
current_timesteps 203000
fps 1417
policy_entropy 0.3719944953918457
value_loss 5.033334732055664
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 78.25
max (last 100): 392.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 204000
current_timesteps 204000
fps 1419
policy_entropy 0.3182474970817566
value_loss 8.911028861999512
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 72.46
max (last 100): 256.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 205000
current_timesteps 205000
fps 1420
policy_entropy 0.38014692068099976
value_loss 1.3709056377410889
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 57.03
max (last 100): 230.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 206000
current_timesteps 206000
fps 1421
policy_entropy 0.3899732828140259
value_loss 0.3242641091346741
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 71.02
max (last 100): 334.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 207000
current_timesteps 207000
fps 1422
policy_entropy 0.4232320487499237
value_loss 2.222675323486328
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 70.03
max (last 100): 215.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 208000
current_timesteps 208000
fps 1423
policy_entropy 0.35069990158081055
value_loss 0.5876952409744263
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 72.83
max (last 100): 303.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 209000
current_timesteps 209000
fps 1424
policy_entropy 0.4015696346759796
value_loss 0.27856600284576416
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 73.7
max (last 100): 393.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 210000
current_timesteps 210000
fps 1425
policy_entropy 0.33423805236816406
value_loss 2.3214781284332275
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 79.92
max (last 100): 426.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 211000
current_timesteps 211000
fps 1426
policy_entropy 0.3708198368549347
value_loss 13.262284278869629
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 56.45
max (last 100): 206.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 212000
current_timesteps 212000
fps 1427
policy_entropy 0.3937753736972809
value_loss 1.901041865348816
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 94.75
max (last 100): 386.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 213000
current_timesteps 213000
fps 1428
policy_entropy 0.2806587815284729
value_loss 7.163145065307617
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 68.06
max (last 100): 216.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 214000
current_timesteps 214000
fps 1429
policy_entropy 0.32841816544532776
value_loss 5.0399627685546875
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 80.61
max (last 100): 334.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 215000
current_timesteps 215000
fps 1429
policy_entropy 0.30638745427131653
value_loss 0.27692726254463196
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 77.39
max (last 100): 250.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 216000
current_timesteps 216000
fps 1430
policy_entropy 0.39891543984413147
value_loss 5.3615827560424805
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 71.91
max (last 100): 401.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 217000
current_timesteps 217000
fps 1431
policy_entropy 0.42850953340530396
value_loss 7.636835098266602
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 78.77
max (last 100): 321.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 218000
current_timesteps 218000
fps 1432
policy_entropy 0.46239370107650757
value_loss 3.3961050510406494
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 70.96
max (last 100): 360.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 219000
current_timesteps 219000
fps 1433
policy_entropy 0.3168259859085083
value_loss 0.4680679142475128
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 84.95
max (last 100): 390.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 220000
current_timesteps 220000
fps 1434
policy_entropy 0.35879167914390564
value_loss 0.7474238872528076
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 76.62
max (last 100): 537.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 221000
current_timesteps 221000
fps 1435
policy_entropy 0.3806689381599426
value_loss 0.297420859336853
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 82.54
max (last 100): 329.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 222000
current_timesteps 222000
fps 1436
policy_entropy 0.32069212198257446
value_loss 1.115443468093872
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 72.39
max (last 100): 411.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 223000
current_timesteps 223000
fps 1436
policy_entropy 0.3142840266227722
value_loss 0.48751094937324524
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 95.1
max (last 100): 402.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 224000
current_timesteps 224000
fps 1437
policy_entropy 0.33027130365371704
value_loss 0.46249738335609436
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 82.38
max (last 100): 250.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 225000
current_timesteps 225000
fps 1438
policy_entropy 0.5123326182365417
value_loss 5.059904098510742
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 75.31
max (last 100): 370.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 226000
current_timesteps 226000
fps 1439
policy_entropy 0.30687713623046875
value_loss 0.4896742105484009
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 74.39
max (last 100): 500.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 227000
current_timesteps 227000
fps 1440
policy_entropy 0.41017982363700867
value_loss 1.6161872148513794
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 76.45
max (last 100): 299.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 228000
current_timesteps 228000
fps 1441
policy_entropy 0.27289173007011414
value_loss 1.0614590644836426
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 75.66
max (last 100): 439.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 229000
current_timesteps 229000
fps 1441
policy_entropy 0.341203898191452
value_loss 0.8250317573547363
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 63.95
max (last 100): 302.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 230000
current_timesteps 230000
fps 1442
policy_entropy 0.4515420198440552
value_loss 9.31325912475586
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 88.05
max (last 100): 424.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 231000
current_timesteps 231000
fps 1443
policy_entropy 0.4279286563396454
value_loss 9.15878677368164
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 83.25
max (last 100): 370.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 232000
current_timesteps 232000
fps 1444
policy_entropy 0.34704458713531494
value_loss 7.243024826049805
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 75.5
max (last 100): 326.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 233000
current_timesteps 233000
fps 1444
policy_entropy 0.3105997145175934
value_loss 0.8160025477409363
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 80.86
max (last 100): 411.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 234000
current_timesteps 234000
fps 1445
policy_entropy 0.35123345255851746
value_loss 0.3859667479991913
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 89.78
max (last 100): 430.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 235000
current_timesteps 235000
fps 1446
policy_entropy 0.3580058515071869
value_loss 0.666063666343689
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 79.74
max (last 100): 315.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 236000
current_timesteps 236000
fps 1447
policy_entropy 0.4072055220603943
value_loss 2.8461852073669434
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 75.99
max (last 100): 335.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 237000
current_timesteps 237000
fps 1448
policy_entropy 0.2923666536808014
value_loss 0.351992130279541
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 89.98
max (last 100): 430.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 238000
current_timesteps 238000
fps 1448
policy_entropy 0.4209851920604706
value_loss 11.606210708618164
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 88.58
max (last 100): 298.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 239000
current_timesteps 239000
fps 1449
policy_entropy 0.32097235321998596
value_loss 8.81591796875
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 66.17
max (last 100): 331.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 240000
current_timesteps 240000
fps 1450
policy_entropy 0.3252824544906616
value_loss 5.735627174377441
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 79.86
max (last 100): 278.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 241000
current_timesteps 241000
fps 1451
policy_entropy 0.28264570236206055
value_loss 0.25918394327163696
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 69.33
max (last 100): 239.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 242000
current_timesteps 242000
fps 1453
policy_entropy 0.3222539722919464
value_loss 0.7003181576728821
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 89.63
max (last 100): 508.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 243000
current_timesteps 243000
fps 1454
policy_entropy 0.32835766673088074
value_loss 0.8329150080680847
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 87.75
max (last 100): 319.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 244000
current_timesteps 244000
fps 1454
policy_entropy 0.4153200089931488
value_loss 7.573360919952393
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 89.53
max (last 100): 428.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 245000
current_timesteps 245000
fps 1455
policy_entropy 0.35845133662223816
value_loss 1.0685964822769165
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 81.39
max (last 100): 299.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 246000
current_timesteps 246000
fps 1455
policy_entropy 0.2911856472492218
value_loss 1.8517134189605713
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 94.64
max (last 100): 417.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 247000
current_timesteps 247000
fps 1456
policy_entropy 0.3284572660923004
value_loss 1.5457713603973389
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 83.54
max (last 100): 340.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 248000
current_timesteps 248000
fps 1457
policy_entropy 0.3212851285934448
value_loss 13.893567085266113
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 106.47
max (last 100): 384.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 249000
current_timesteps 249000
fps 1457
policy_entropy 0.4573429822921753
value_loss 2.118412494659424
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 90.62
max (last 100): 513.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 250000
current_timesteps 250000
fps 1458
policy_entropy 0.254453182220459
value_loss 0.32139110565185547
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 81.94
max (last 100): 404.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 251000
current_timesteps 251000
fps 1458
policy_entropy 0.40305837988853455
value_loss 0.5475607514381409
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 114.95
max (last 100): 329.0
Saved_the_max_model
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 252000
current_timesteps 252000
fps 1459
policy_entropy 0.32362696528434753
value_loss 0.3690824806690216
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 92.17
max (last 100): 421.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 253000
current_timesteps 253000
fps 1459
policy_entropy 0.397310346364975
value_loss 1.5137038230895996
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 87.5
max (last 100): 496.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 254000
current_timesteps 254000
fps 1460
policy_entropy 0.2746536433696747
value_loss 3.7611591815948486
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 92.5
max (last 100): 399.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 255000
current_timesteps 255000
fps 1460
policy_entropy 0.46260949969291687
value_loss 0.7822448015213013
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 75.28
max (last 100): 357.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 256000
current_timesteps 256000
fps 1461
policy_entropy 0.3742000162601471
value_loss 0.5287560224533081
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 82.93
max (last 100): 256.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 257000
current_timesteps 257000
fps 1461
policy_entropy 0.3524051606655121
value_loss 0.52485191822052
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 77.47
max (last 100): 522.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 258000
current_timesteps 258000
fps 1462
policy_entropy 0.2786480188369751
value_loss 0.5841102004051208
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 78.32
max (last 100): 417.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 259000
current_timesteps 259000
fps 1462
policy_entropy 0.429532915353775
value_loss 0.21923865377902985
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 91.92
max (last 100): 437.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 260000
current_timesteps 260000
fps 1463
policy_entropy 0.48775407671928406
value_loss 3.066373825073242
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 93.47
max (last 100): 476.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 261000
current_timesteps 261000
fps 1463
policy_entropy 0.40024229884147644
value_loss 0.2870178520679474
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 86.75
max (last 100): 463.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 262000
current_timesteps 262000
fps 1464
policy_entropy 0.35177338123321533
value_loss 0.8482977747917175
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 88.39
max (last 100): 445.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 263000
current_timesteps 263000
fps 1464
policy_entropy 0.31845900416374207
value_loss 3.844024658203125
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 87.67
max (last 100): 371.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 264000
current_timesteps 264000
fps 1465
policy_entropy 0.2673892676830292
value_loss 0.41414758563041687
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 83.71
max (last 100): 559.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 265000
current_timesteps 265000
fps 1465
policy_entropy 0.3844650685787201
value_loss 0.3357180953025818
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 77.73
max (last 100): 487.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 266000
current_timesteps 266000
fps 1466
policy_entropy 0.32454511523246765
value_loss 0.4748770296573639
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 83.07
max (last 100): 407.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 267000
current_timesteps 267000
fps 1466
policy_entropy 0.39363181591033936
value_loss 0.41798317432403564
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 113.04
max (last 100): 518.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 268000
current_timesteps 268000
fps 1467
policy_entropy 0.3721488118171692
value_loss 0.3177711069583893
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 85.76
max (last 100): 393.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 269000
current_timesteps 269000
fps 1467
policy_entropy 0.3759722411632538
value_loss 1.3732327222824097
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 88.3
max (last 100): 452.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 270000
current_timesteps 270000
fps 1468
policy_entropy 0.33476197719573975
value_loss 0.7206799983978271
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 93.92
max (last 100): 361.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 271000
current_timesteps 271000
fps 1468
policy_entropy 0.47381484508514404
value_loss 1.6005734205245972
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 90.41
max (last 100): 349.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 272000
current_timesteps 272000
fps 1469
policy_entropy 0.3640892505645752
value_loss 6.472519874572754
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 74.43
max (last 100): 327.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 273000
current_timesteps 273000
fps 1469
policy_entropy 0.4759191870689392
value_loss 7.423254013061523
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 87.17
max (last 100): 420.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 274000
current_timesteps 274000
fps 1469
policy_entropy 0.29789769649505615
value_loss 0.4195365309715271
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 69.34
max (last 100): 328.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 275000
current_timesteps 275000
fps 1470
policy_entropy 0.36512744426727295
value_loss 0.47885581851005554
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 99.66
max (last 100): 434.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 276000
current_timesteps 276000
fps 1470
policy_entropy 0.3514496088027954
value_loss 3.483060359954834
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 97.81
max (last 100): 493.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 277000
current_timesteps 277000
fps 1471
policy_entropy 0.4246375858783722
value_loss 0.2809008061885834
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 94.62
max (last 100): 423.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 278000
current_timesteps 278000
fps 1471
policy_entropy 0.41465678811073303
value_loss 3.8451435565948486
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 95.95
max (last 100): 417.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 279000
current_timesteps 279000
fps 1472
policy_entropy 0.397939532995224
value_loss 2.278182029724121
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 108.32
max (last 100): 403.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 280000
current_timesteps 280000
fps 1472
policy_entropy 0.43997669219970703
value_loss 3.0078859329223633
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 79.29
max (last 100): 487.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 281000
current_timesteps 281000
fps 1473
policy_entropy 0.2952057123184204
value_loss 0.39072588086128235
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 112.47
max (last 100): 502.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 282000
current_timesteps 282000
fps 1473
policy_entropy 0.3269730806350708
value_loss 0.4503670334815979
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 106.84
max (last 100): 579.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 283000
current_timesteps 283000
fps 1473
policy_entropy 0.2568930387496948
value_loss 0.47639691829681396
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 106.99
max (last 100): 452.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 284000
current_timesteps 284000
fps 1474
policy_entropy 0.3856104910373688
value_loss 0.72780841588974
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 82.45
max (last 100): 491.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 285000
current_timesteps 285000
fps 1474
policy_entropy 0.3991764187812805
value_loss 1.1130880117416382
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 98.54
max (last 100): 421.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 286000
current_timesteps 286000
fps 1475
policy_entropy 0.4221609830856323
value_loss 0.2789299786090851
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 99.08
max (last 100): 432.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 287000
current_timesteps 287000
fps 1475
policy_entropy 0.40209972858428955
value_loss 0.4370160698890686
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 92.11
max (last 100): 605.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 288000
current_timesteps 288000
fps 1476
policy_entropy 0.37491875886917114
value_loss 1.2683584690093994
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 106.27
max (last 100): 539.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 289000
current_timesteps 289000
fps 1476
policy_entropy 0.2873969078063965
value_loss 8.484904289245605
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 95.52
max (last 100): 336.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 290000
current_timesteps 290000
fps 1476
policy_entropy 0.44962140917778015
value_loss 0.40705588459968567
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 92.85
max (last 100): 445.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 291000
current_timesteps 291000
fps 1477
policy_entropy 0.4852967858314514
value_loss 1.59902024269104
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 104.13
max (last 100): 467.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 292000
current_timesteps 292000
fps 1478
policy_entropy 0.3822113275527954
value_loss 0.5421186089515686
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 100.19
max (last 100): 430.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 293000
current_timesteps 293000
fps 1478
policy_entropy 0.34000885486602783
value_loss 0.41660720109939575
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 96.37
max (last 100): 491.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 294000
current_timesteps 294000
fps 1479
policy_entropy 0.28981268405914307
value_loss 8.092522621154785
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 105.43
max (last 100): 493.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 295000
current_timesteps 295000
fps 1479
policy_entropy 0.42628806829452515
value_loss 1.0397759675979614
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 114.37
max (last 100): 438.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 296000
current_timesteps 296000
fps 1480
policy_entropy 0.43811824917793274
value_loss 0.3499452769756317
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 89.94
max (last 100): 361.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 297000
current_timesteps 297000
fps 1480
policy_entropy 0.4042474031448364
value_loss 0.5380473732948303
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 105.54
max (last 100): 467.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 298000
current_timesteps 298000
fps 1481
policy_entropy 0.42783570289611816
value_loss 0.7745495438575745
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 102.21
max (last 100): 507.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 299000
current_timesteps 299000
fps 1482
policy_entropy 0.3893122375011444
value_loss 1.283736228942871
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 110.62
max (last 100): 476.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 300000
current_timesteps 300000
fps 1482
policy_entropy 0.2986330986022949
value_loss 0.4461466073989868
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 112.44
max (last 100): 497.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 301000
current_timesteps 301000
fps 1483
policy_entropy 0.3472294509410858
value_loss 3.5407562255859375
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 98.64
max (last 100): 544.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 302000
current_timesteps 302000
fps 1483
policy_entropy 0.36249881982803345
value_loss 0.8329861164093018
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 101.69
max (last 100): 592.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 303000
current_timesteps 303000
fps 1484
policy_entropy 0.3957892060279846
value_loss 4.446918964385986
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 108.99
max (last 100): 459.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 304000
current_timesteps 304000
fps 1484
policy_entropy 0.39287713170051575
value_loss 1.0599271059036255
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 104.65
max (last 100): 590.0
Saved_the_model
No_of_times_loop_run 305555
 - - - - - - - 
nupdates 305000
current_timesteps 305000
fps 1485
policy_entropy 0.38435328006744385
value_loss 13.279315948486328
total_no 305556
avg reward (last 100): -1.0
avg total reward (last 100): 103.68
max (last 100): 474.0
Saved_the_model
